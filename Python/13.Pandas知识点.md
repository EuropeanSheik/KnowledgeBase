# 一、Pandas基础知识

### 1. 安装和使用

```bash
pip install pandas
```

```python
import numpy as np
import pandas as pd
```

### 2. Pandas的特点

- `具有极强的自适应能力`。无论是Python还是NumPy的数据对象，即使是结构不规则的数据也可以轻松转换为DataFrame。Pandas还可以自动处理确实数据，类似NumPy的掩码数组
- `NumPy为其提供了快速的数据组织和处理能力`。Pandas支持任意增删数据列，支持合并、连接、重塑、透视数据集，支持聚合、转换、切片、花式索引、子集分解等操作
- `拥有全面的I/O工具`。Pandas支持读取文本文件（CSV等支持分隔符的文件）、Excel文件、HDF文件、SQL表数据、json数据、html数据，甚至可以直接从url下载并解析数据，也可以将数据保存为CSV文件或Excel文件
- `完善的时间序列`。Pandas支持日期范围生成、频率转换、移动窗口统计、移动窗口线性回归、日期移位等时间序列功能
- `对用户友好的显示格式`。不管数据复杂程度如何，Pandas展现出的数据结构总是最清晰的，它支持自动对齐对象和标签，必要时也可以忽略标签

# 二、Pandas的数据结构

### 1. 索引Index

索引类似一维数组，在Pandas的其他数据结构中作为标签使用。

```python
import pandas as pd

print(pd.Index([3,4,5]))
print(pd.Index(['x','y','z']))
print(pd.Index(range(3)))
idx = pd.Index(['x','y','z'])
print(idx)
```

使用数组、列表、迭代器等都可以创建索引。索引看起来像一维数组，但无法修改元素的值。除了以为索引数据组，还有时间纳秒级戳索引、层次化索引等。此外，索引也有删除、插入、连接、交集、并集等操作

### 2. 带标签的一维同构数组Series

Series是由一组同一类型的数据和一组与数据对应的标签(Index)组成的数据结构，数据对应的标签又称为索引，索引是允许重复的。

如果不指定索引，Series生成器自动添加默认索引。默认索引是从0开始的整型数列

```python
print(pd.Series([0,1,2])) # 用列表生成Series，使用默认索引
print(pd.Series(['a','b','c'])) # 用列表生成Series，使用默认索引
```

创建Series时，也可以同时指定索引。不过，索引长度一定要和列表长度相等，否则会抛出异常。另外，Series生成器也接受迭代对象作为参数

```python
print(pd.Series([0,1,2], index=['a','b','c'])) # 用列表生成Series
print(pd.Series(range(3), index=list('abc'))) # 用迭代对象生成Series
```

使用字典创建Series时，如果没有指定索引，则使用字典的键作为索引；如果指定了索引，则不要求和字典的键匹配

```python
print(pd.Series({'a':1,'b':2,'c':3})) # 用字典生成Series，使用字典的键做索引
print(pd.Series({'a':1,'b':2,'c':3}, index=list('abxy'))) # 指定索引
```

Series有很多属性和方法，其中大部分和NumPy类似，甚至完全一致

```python
s = pd.Series({'a':1,'b':2,'c':3})
print(s.dtype) # Series对象的数据类型是最重要的三个属性之一
print(s.values) # Series对象的数组是最重要的三个属性之二
print(s.index) # Series对象的索引是最重要的三个属性之三
```

### 3. 带标签的二维异构表格DataFrame

DataFrame可以看做由多个Series组成的二维表格型数据结构。每一个Series作为DataFrame的一列，每一列都有一个列名，都可以拥有独立的数据类型，所有的Series共用一个索引。列名称为DataFrame的列标签，索引称为DataFrame的行标签

将字典转换为DataFrame，字典的键对应DataFrame的列，键名自动称为列名。如果没有指定索引，则使用默认索引

```python
data = {
    '华东科技': [1.91, 1.90, 1.86, 1.84],
    '长安汽车': [11.27, 11.14, 11.28, 11.71],
    '西藏矿业': [7.89, 7.79, 7.61, 7.50],
    '重庆啤酒': [50.46, 50.17, 50.28, 50.28]
}

print(pd.DataFrame(data))
```

创建DataFrame时可以指定索引

```python
idx = ['2020-03-10','2020-03-11','2020-03-12','2020-03-13']
print(pd.DataFrame(data, index=idx))
```

在创建DataFrame时，即使数据以字典形式提供，也可以指定列标签，DataFrame生成器不要求列标签和字典的键全部匹配。对于不存在的键，DataFrame生成器会自动填补NaN值

```python
data = {
    '华东科技': [1.91, 1.90, 1.86, 1.84],
    '长安汽车': [11.27, 11.14, 11.28, 11.71],
    '西藏矿业': [7.89, 7.79, 7.61, 7.50],
    '重庆啤酒': [50.46, 50.17, 50.28, 50.28]
}

idx = ['2020-03-10','2020-03-11','2020-03-12','2020-03-13']
colnames = ['华东科技', '长安汽车', '杭钢股份', '西藏矿业', '重庆啤酒']
print(pd.DataFrame(data, columns=colnames, index=idx))
```

二维数组或列表也可以直接转换成DataFrame，同时可以指定索引和列标签。如果没有指定索引或列标签，DataFrame生成器则会自动添加从0开始的索引对象作为索引或列标签

```python
data = np.array([
    [ 1.91, 11.27,  7.89, 50.46],
    [ 1.9 , 11.14,  7.79, 50.17],
    [ 1.86, 11.28,  7.61, 50.28],
    [ 1.84, 11.71,  7.5 , 50.28]
])

idx = ['2020-03-10','2020-03-11','2020-03-12','2020-03-13']
colnames = ['华东科技', '长安汽车', '西藏矿业', '重庆啤酒']
print(pd.DataFrame(data, columns=colnames, index=idx))
```

DataFrame可以看作多个Series的集合，每个Series都可以拥有各自独立的数据类型，因此，DataFrame没有自身唯一的数据类型，也就没有dtype属性，不过，DataFrame多了一个dtypes属性，这个属性的类型是Series类。

```python
df = pd.DataFrame(data, columns=colnames, index=idx)
print(df.dtypes) # dtypes属性，是由所有列的数据类型组成的Series
print(df.values) # DataFrame的重要属性之一
print(df.index) # DataFrame的重要属性之一
print(df.columns) # DataFrame的重要属性之一
```

# 三、基本操作

`公用数据`

```python
import pandas as pd
import numpy as np

data = np.array([
    [10.70, 11.95, 10.56, 11.71, 789.10, 68771048],
    [7.28, 7.59, 7.17, 7.50, 57.01, 7741802],
    [48.10, 50.59, 48.10, 50.28, 223.06, 4496598],
    [66.70, 69.28, 66.66, 68.92, 1196.14, 17662768],
    [7.00, 7.35, 6.93, 7.11, 783.15, 109975919],
    [2.02, 2.10, 2.01, 2.08, 56.32, 27484360]
])

colnames = ['开盘价','最高价','最低价','收盘价','成交额','成交量']
idx = ['000625.SZ','000762.SZ','600132.SH','600009.SH','600126.SH','000882.SZ']
stock = pd.DataFrame(data, columns=colnames, index=idx)
```

### 1. 数据预览

```python
print(stock.head()) # 从头开始的5行
print(stock.tail()) # 尾部的5行
print(stock.describe()) # 均值、方差、极值的统计概要
print(stock.T) # 转置
print(stock.sort_index(axis=0)) # 按照索引排序
print(stock.sort_values(by='成交量')) # 按照指定列的数值排序
```

### 2. 数据选择

- DataFrame支持类似数组或列表的切片操作，如`stock[2:3]`，但不能像`stock[2]`这样直接索引。还可以对行标签(索引)切片。切片顺序基于DataFrame的Index，返回结果包含指定切片的两个索引项，类似数学的闭区间
- DataFrame仅允许选择单列数据返回Series。如果要选择多列，必须同时指定选择的行
- 使用行列选择器loc可以同时选择行和列。行选择使用切片，列选择使用列表。如果想和访问二维数组一样访问DataFrame，可以使用at、iat或iloc等行列选择器

```python
print(stock[2:3]) # 行选择
print(stock['000762.SZ':'600009.SH']) # 行选择
print(stock['开盘价']) # 列选择。选择单列，也可以使用stock.开盘价
print(stock.loc['000762.SZ':'600009.SH', ['开盘价', '收盘价', '成交量']]) # 行列选择
print(stock.at['000762.SZ', '开盘价']) # 行列选择
print(stock[(stock['成交额']>500)&(stock['开盘价']>10)]) # 条件选择，支持复合条件
print(stock[stock['成交额'].isin([56.32,57.01,223.06])]) # 条件选择，使用isin()筛选多个特定值
```

### 3. 改变数据结构

- DataFrame的`reindex()`函数可以重新定义行标签或列标签，并返回一个新的对象，原有的数据结构不会被改变。重新索引既可以删除已有的行或列，也可以增加新的行或列。如果不指定填充值，新增的行或列的值默认为NaN
- DataFrame的`drop()`函数可以删除指定轴的指定项，返回一个新的对象，原有的数据结构不会被改变
- DataFrame的`append()`函数可以在对象的尾部追加另一个DataFrame，实现行扩展。行扩展并不强制要求两个DataFrame列标签匹配。行扩展会返回一个新的数据结构，其列标签是两个DataFrame的并集。行扩展不会改变原有的数据结构
- Pandas命名空间下的`concat()`函数也可以实现多个DataFrame的垂直连接，比`append()`函数方便
- 直接对新列赋值即可实现列扩展。赋值时，数据长度必须和DataFrame的长度匹配。这里需要注意，其他改变数据结构的操作都是返回新的数据结构，原有的数据结构不会被改变，而赋值操作会改变原有的数据结构

```python
print(stock.reindex(index=idx, columns=colnames)) # 重新索引
print(stock.reindex(index=idx, columns=colnames, fill_value=0)) # 重新索引，指定填充值
print(stock.drop(['000762.SZ', '600132.SH'], axis=0)) # 删除指定行
print(stock.drop(['成交额', '最高价', '最低价'], axis=1)) # 删除指定列

idx = ['600161.SH', '600169.SH']
colnames = ['开盘价', '收盘价', '成交额', '成交量', '涨跌幅']
data = np.array([
    [31.00, 32.16, 284.02, 8932594, 0.03],
    [2.02, 2.13, 115.87, 54146894, 0.05]
])
s = pd.DataFrame(data, columns=colnames, index=idx)
print(stock.append(s)) # 行扩展
print(pd.concat((stock, s))) # 行扩展

stock['涨跌幅'] = [0.02, 0.03, 0.05, 0.01, 0.02, 0.03] # 列扩展，改变了原有的数据结构
print(stock)
```

### 4. 改变数据类型

- 类似NumPy数组，Series提供了`astype()`函数来改变数据类型。不过`astype()`函数只是返回了一个新的`Series`，并没有真正改变原有的Series。DataFrame没有提供改变某一列数据类型的方法，如果想要这样做，则需要对这一列重新赋值

```python
print(stock['涨跌幅'].dtype) # dtype('float64')
stock['涨跌幅'] = stock['涨跌幅'].astype('float32').values
print(stock['涨跌幅'].dtype) # dtype('float32')
```

### 5. 广播与矢量化运算

- Pandas是基于NumPy数组的扩展，继承了NumPy数组的广播和矢量化特性。不管是Series内部，还是Series之间，甚至是DataFrame之间，所有的运算都支持广播和矢量化。此外，NumPy数组的数学和统计函数几乎都可以应用在Pandas的数据结构上
- 对DataFrame进行广播运算同样是可行的，两个DataFrame之间也可以进行算数运算。两个DataFrame进行算数运算时，对应列标签的索引项之间做算数运算，无对应项的元素自动填充NaN值

```python
stock['成交量'] /= 2 # 成交量减半
print(stock)

stock['最高价'] += stock['最低价'] # 最高价加上最低价
print(stock)

stock['开盘价'] = (stock['开盘价']-stock['开盘价'].mean())/stock['开盘价'].std() # 开盘价标准化
print(stock)

df_a = pd.DataFrame(np.arange(6).reshape((2,3)), columns=list('abc'))
df_b = pd.DataFrame(np.arange(6,12).reshape((3,2)), columns=list('ab'))

print(df_a + 1) # 对DataFrame对象的广播运算
print(df_a + df_b) # 两个DataFrame对象的矢量运算
```

### 6. 行列级广播函数

- NumPy数组的大部分数学函数和统计函数都是广播函数，可以被隐式地映射到数组的各个元素上。NumPy数组支持自定义广播函数。Panas的`apply()`函数类似于NumPy数组的自定义广播函数，可以将函数映射到DataFrame的特定行或列上，也就是以行或列的一维数组作为函数的输入参数，而不是以行或列的各个元素作为函数的输入参数。这是Pandas的`apply()`函数有别于NumPy数组自定义广播函数的地方

```python
f = lambda x:(x-x.min())/(x.max()-x.min()) # 定义归一化函数
print(stock.apply(f, axis=0)) # 0轴（行方向）归一化
print(stock.apply(f, axis=1)) # 1轴（列方向）归一化
```

# 四、高级应用

### 1. 分组

`需求：对多只股票多个交易日的成交量分析，需要按股票和交易日两种分类方式进行统计`

```python
import pandas as pd

data = {
    '日期': ['2020-03-11','2020-03-11','2020-03-11','2020-03-11','2020-03-11',
            '2020-03-12','2020-03-12','2020-03-12','2020-03-12','2020-03-12',
            '2020-03-13','2020-03-13','2020-03-13','2020-03-13','2020-03-13'],
    '代码': ['000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ',
            '000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ',
            '000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ'],
    '成交额': [422.08,73.65,207.04,510.59,63.28,
            471.78,59.2,156.82,853.83,52.84,
            789.1,57.01,223.06,1196.14,56.32],
    '成交量': [37091400,9315300,4127800,7233100,28911100,
            42471700,7724200,3143100,12350400,24828900,
            68771048,7741802,4496598,17662768,27484360]
}

vo = pd.DataFrame(data)
```

使用`groupby()`函数按照日期分组，返回的分组结果是一个迭代器，遍历这个迭代器，可以得到3个由组名（日期）和该组的DataFrame组成的元组

```python
for name, df in vo.groupby('日期'):
    print('组名：%s'%name)
    print('-------------------------------------------')
    print(df)
    print()
```

使用`groupby()`函数按照股票代码分组，返回的分组结果是一个迭代器，遍历这个迭代器，可以得到5个由组名（股票代码）和该组的DataFrame组成的元组

```python
for name, df in vo.groupby('代码'):
    print('组名：%s'%name)
    print('-------------------------------------------')
    print(df)
    print()
```

### 2. 聚合

`要求：统计所有股票每天的成交总额和成交总量等`

可以直接应用在分组结果上的函数包括计数(count)、求和(sum)、均值(mean)、中位数(median)、有效值的乘积(prod)、方差(var)和标准差(std)、最大值(max)和最小值(min)、第一个有效值(first)、最后一个有效值(last)等

```python
import pandas as pd

data = {
    '日期': ['2020-03-11','2020-03-11','2020-03-11','2020-03-11','2020-03-11',
            '2020-03-12','2020-03-12','2020-03-12','2020-03-12','2020-03-12',
            '2020-03-13','2020-03-13','2020-03-13','2020-03-13','2020-03-13'],
    '代码': ['000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ',
            '000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ',
            '000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ'],
    '成交额': [422.08,73.65,207.04,510.59,63.28,
            471.78,59.2,156.82,853.83,52.84,
            789.1,57.01,223.06,1196.14,56.32],
    '成交量': [37091400,9315300,4127800,7233100,28911100,
            42471700,7724200,3143100,12350400,24828900,
            68771048,7741802,4496598,17662768,27484360]
}

vo = pd.DataFrame(data)

print(vo.groupby('日期').sum()) # 按日期统计全部股票的成交总额和成交总量
print(vo.groupby('代码').mean()) # 统计各个股票的多个交易日的平均成交额和平均成交量
```

如果对分组结果实施自定义的函数，或对分组结果做更多的统计分析，此时就要用到聚合函数`agg()`

```python
def scope(x): # 返回最大值和最小值之差（波动幅度）的函数
    return x.max()-x.min()

print(vo.groupby('代码').agg(scope)) # 统计每一只股票成交额和成交量的波动幅度
print(vo.groupby('代码').agg(['mean', scope])) # 统计成交额和成交量的均值和波动幅度
```

聚合函数`agg()`还可以对不同的列实施不同的函数操作。例如，下面的代码对成交额实施均值操作，对成交量实施自定义的波动幅度函数

```python
print(vo.groupby('代码').agg({'成交额':'mean', '成交量':scope})) # 对成交额实施均值操作，对成交量实施自定义的波动幅度函数
```

### 3. 层次化索引

```python
import pandas as pd
import numpy as np

dt = ['2020-03-11', '2020-03-12','2020-03-13']
sc = ['000625.SZ','000762.SZ','600132.SH','600009.SH','600126.SH']
cn = ['成交额', '成交量']
idx = pd.MultiIndex.from_product([dt, sc], names=['日期', '代码'])
data = np.array([
	[422.08, 37091400],
	[73.65, 9315300],
	[207.04, 4127800],
	[510.59, 7233100],
	[63.28, 28911100],
	[471.78, 42471700],
	[59.2, 7724200],
	[156.82, 3143100],
	[853.83, 12350400],
	[52.84, 24828900],
	[789.1, 68771048],
	[57.01, 7741802],
	[223.06, 4496598],
	[1196.14, 17662768],
	[56.32, 27484360]
])

vom1 = pd.DataFrame(data, index=idx, columns=cn)
print(vom1)
```

层次化索引数据`vom1`有日期和代码两个索引项。层次化索引还有另外一种形式，即在行标签上使用层次化索引

```python
dt = ['2020-03-11', '2020-03-12','2020-03-13']
sc = ['000625.SZ','000762.SZ','600132.SH','600009.SH','000882.SZ']
cn = ['成交额', '成交量']
cols = pd.MultiIndex.from_product([dt, cn], names=['日期', '数据'])
data = np.array([
	[422.08, 37091400, 471.78, 42471700, 789.1, 68771048],
	[73.65, 9315300, 59.2, 7724200, 57.01, 7741802],
	[207.04, 4127800, 156.82, 3143100, 223.06, 4496598],
	[510.59, 7233100, 853.83, 12350400, 1196.14, 17662768],
	[63.28, 28911100, 52.84, 24828900, 56.32, 27484360]
])

vom2 = pd.DataFrame(data, index=sc, columns=cols)
print(vom2)
```

层次化索引数据的索引和选择类似普通的DataFrame对象

```python
print(vom1.loc['2020-03-11'])
print(vom1.loc['2020-03-11', '000625.SZ'])
print(vom1.loc['2020-03-11', '000625.SZ']['成交量'])

print(vom2['2020-03-11'])
print(vom2['2020-03-11', '成交额'])
print(vom2.loc['000625.SZ'])
print(vom2.loc['000625.SZ'][:,'成交额'])
```

### 4. 表级广播函数

行列级广播函数`apply()`可以把一个计算函数映射到DataFrame的行或列上，并以行或列的一维数组作为计算函数的输入参数。与`apply()`函数类似，表级广播函数`pipe()`可以把一个计算函数映射到DataFrame的每一个元素上，并以每一个元素作为计算函数的第一个输入参数

```python
import pandas as pd
import numpy as np

dt = ['2020-03-11', '2020-03-12','2020-03-13']
sc = ['000625.SZ','000762.SZ','600132.SH','600009.SH','600126.SH']
cn = ['成交额', '成交量']
idx = pd.MultiIndex.from_product([dt, sc], names=['日期', '代码'])
data = np.array([
	[422.08, 37091400],
	[73.65, 9315300],
	[207.04, 4127800],
	[510.59, 7233100],
	[63.28, 28911100],
	[471.78, 42471700],
	[59.2, 7724200],
	[156.82, 3143100],
	[853.83, 12350400],
	[52.84, 24828900],
	[789.1, 68771048],
	[57.01, 7741802],
	[223.06, 4496598],
	[1196.14, 17662768],
	[56.32, 27484360]
])

vom1 = pd.DataFrame(data, index=idx, columns=cn)
print(vom1)

def scale(x, k): # 对x进行缩放，缩放系数为k
    return x*k

print(vom1.pipe(scale, 0.2)) # 对vom1所有数据执行缩放函数，缩放系数0.2
```

`pipe()`函数将DataFrame作为首个参数，这为链式调用提供了可能性。

```python
def adder(x, dx):
    return x+dx
print(vom1.pipe(scale, 0.2).pipe(adder, 5)) # 链式调用
```

### 5. 日期时间索引

`DatetimeIndex`类是索引数组的一种，也是常用的日期时间序列生成和转换工具，既可以由日期时间字符串列表直接生成日期时间索引，也可以将字符串类型的索引、Series转换成日期时间索引



```python
import pandas as pd

print(pd.DatetimeIndex(['2020-03-10', '2020-03-11', '2020-03-12']))
print(pd.DatetimeIndex(pd.Index(['2020-03-10', '2020-03-11', '2020-03-12'])))

idx = pd.Index(['2020-03-10', '2020-03-11', '2020-03-12'])
sdt = pd.Series(['2020-03-10', '2020-03-11', '2020-03-12'])

print(idx)
print(sdt)
print(pd.DatetimeIndex(idx))
print(pd.DatetimeIndex(sdt))
```

转换函数`pd.to_datetime()`的功能类似于`DatetimeIndex`类，可以将各种格式的日期时间字符串转换为日期时间索引

```python
print(pd.to_datetime(['2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13']))
print(pd.to_datetime(idx))
print(pd.to_datetime(sdt))
```

给定起止时间、序列长度或分割步长，`date_range()`函数也可以快速创建日期时间索引。分割步长使用`L`、`S`、`T`、`H`、`D`、`M`分别表示毫秒、秒、分钟、小时、天、月等，还可以加上数字，如3H表示分割步长为3小时

```python
print(pd.date_range(start='2020-05-12', end='2020-05-18'))
print(pd.date_range(start='2020-05-12 08:00:00', periods=6, freq='3H'))
print(pd.date_range(start='08:00:00', end='9:00:00', freq='15T'))
```

### 6. 数据可视化

Pandas的数据可视化是基于Matplotlib的一个封装，但封装的不够彻底，很多地方仍然离不开Matplotlib。例如，脱离ipython或jupyter的环境，必须要使用`pyplot.show()`函数才能显示绘图结果，解决中文显示问题也必须要显式地导入`matplotlib.pyplot`包，除非手动修改`Matplotlib`的字体配置文件

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = ['FangSong']
plt.rcParams['axes.unicode_minus'] = False
```

Pandas的数据可视化API提供了绘制折线图、柱状图、箱线图、直方图、散点图、饼图等功能。对于Series和DataFrame的数据可视化，通常以x轴表示索引，以y轴表示数据

```python
idx = pd.date_range(start='08:00:00',end='9:00:00',freq='T') # 间隔1分钟
y = np.sin(np.linspace(0,2*np.pi,61)) # 0~2π之间61个点的正弦值
s = pd.Series(y, index=idx) # 创建Series对象，索引是时间序列
s.plot() # 绘制折线图
plt.show() # 显示绘图结果
```

对DataFrame的数据可视化也是以x轴表示索引，多列数据既可以绘制在画布的同一个子图上，也可以绘制在同一张画布的多个子图上

```python
data = np.random.randn(10,4)
idx = pd.date_range('08:00:00', periods=10, freq='H')
df = pd.DataFrame(data, index=idx, columns=list('ABCD'))
df.plot()
plt.show()
```

```python
df = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'))
fig = plt.figure( )
ax = fig.add_subplot(131)
df.plot.bar(ax=ax)
ax = fig.add_subplot(132)
df.plot.bar(ax=ax, stacked=True)
ax = fig.add_subplot(133)
df.plot.barh(ax=ax, stacked=True)
plt.show()
```

### 7. 数据I/O

##### 7.1 读写CSV格式的数据文件

写CSV格式的数据文件时，索引会被写入首列（0列）；读取数据时，如果没有指定首列（0列）为索引，则读取的数据被自动添加默认索引

```python
import pandas as pd
import numpy as np

# 1. 读写CSV格式的数据文件
df = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD')) # 生成模拟数据
df.to_csv(r'..\res\random.csv') # 保存为CSV文件

df = pd.read_csv(r'..\res\random.csv') # 读取CSV文件
print(df)
```

读取数据时可以使用`index_col`参数指定首列(0列)为索引

```python
df = pd.read_csv(r'D:\NumPyFamily\data\random.csv', index_col=0) # 读取CSV文件时，使用index_col参数指定首列（0列）为索引
print(df)
```

##### 7.2 读写Excel文件

读写Excel文件时需要用`sheet_name`参数指定表名。写Excel文件时，索引会被写入首列（0列）；读取数据时，如果没有指定首列（0列）为索引，则会自动添加默认索引

```python
idx = pd.date_range('08:00:00', periods=10, freq='H')
df = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'),index=idx)
df.to_excel(r'..\res\random.xlsx', sheet_name='随机数') # 保存为xecel文件

df = pd.read_excel(r'..\res\random.xlsx', sheet_name='随机数') # 读取xecel文件
print(df)
```

读取数据时，可以使用`index_col`参数指定首列(0列)为索引

```python
df = pd.read_excel(r'..\res\random.xlsx', sheet_name='随机数', index_col=0) # 读取xecel文件，使用index_col参数指定首列（0列）为索引
print(df)
```

##### 7.3 读写HDF文件

将数据写入HDF文件时，需要使用key参数指定数据集的名字。如果HDF文件已经存在，`to_hdf()`函数会以追加方式写入新的数据集

```python
idx = pd.date_range('08:00:00', periods=10, freq='H')
df = pd.DataFrame(np.random.rand(10,4),columns=list('ABCD'),index=idx)
df.to_hdf(r'..\res\random.h5', key='random') # 保存为HDF文件

df = pd.read_hdf(r'..\res\random.h5', key='random') # 读取HDF文件
print(df)
```

# 五、Pandas扩展

### 1. 统计扩展模块Statsmodels

Statsmodels是著名的统计扩展模块，其使用Pandas作为计算的底层数据容器，与Pandas密不可分。 Statsmodels提供了比Pandas更加强大的统计数据功能，包括计量经济学、分析和建模等。

##### 1. stasmodels.api

用于线性回归（普通最小二乘线性回归、加权最小二乘线性回归、广义最小二乘线性回归）

- `stasmodels.api.OLS(endog, exog, missing, hasconst)`
- `stasmodels.api.OLS(endog, exog, missing, hasconst).fit()`
- `stasmodels.api.GLS(endog, exog, sigma, missing, hasconst)`
- `stasmodels.api.WLS(endog, exog, weights, missing, hasconst)`

##### 2. statsmodels.stats

提供了丰富的统计检验工具，可以独立应用在`statsmodel.api`或`statsmodels.tsa`建立的统计模型中

- `statsmodels.stats.jarque_beta`函数用于正态性检验
- `statsmodels.stats.robust_skewness`函数和`statsmodels.stats.robust_kurtosis`函数用于计算偏度和峰度，一般也用于正态性检验
- `statsmodels.stats.acorr_ljungbox`函数可以给出更详细的`L-B`检验统计量和P值，包含大量样本情况下的Q统计量检验和小样本情况下改进后的`L-B`检验

##### 3. statsmodels.tsa

用于时间序列建模分析。`statsmodels.tsa`包括基本的线性时间序列模型：自回归模型AR、向量自回归模型VAR、自回归移动平均模型ARMA，以及非线性的马尔代夫转化模型`Markov switching dynamic regreesion and autoregression`。另外也可以获取时间序列的描述统计量，例如该序列的自相关系数和偏自相关系数。模型的参数估计方法可使用条件最大似然和条件最小二乘，卡尔曼滤波也在可选参数范围内

##### 4. statsmodels.graphics

为各种统计模型提供了绘图工具

- `qqplot`函数（在`statsmodels.graphics.boxplots.violinplot`函数)
- `boxplots`类中的小提琴图`statsmodels.graphics.boxplots.violinplot`函数
- 相关系数类中的`statsmodels.graphiccs.correlation.plot_corr`函数
- 回归模型中的`statsmodels.graphics.regressionplots.plot_regress_exog`函数
- 时间序列模型中的`statsmodels.graphics.tasaplots.plot_acf`和`plot_pacf`函数

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
from statsmodels.datasets.longley import load_pandas

df = load_pandas().data
print(df)
```

该DataFrame共有7列数据，第一列是总就业数，为因变量；后几列分别是GNP平减指数、GNP、失业数、武装力量规模、人口、年份。下面用后几列作为解释变量，对因变量做基础的最小二乘法回归

```python
y = load_pandas().endog
X = load_pandas().exog
X = sm.add_constant(X)
ols_model = sm.OLS(y,X).fit()
print(ols_model.summary())
```

### 2. 可视化扩展Seaborn

类似Pandas的数据可视化API，Seaborn也是基于Matplotlib实现的可视化库。它提供面向数据集的高度交互式API，可以让用户轻松画出更加美观的图形。Seaborn的美观主要体现在配色更加和谐，以及图形元素的样式更加细腻上。Seaborn高度兼容NumPy和Pandas的数据结构，可以在绘制图表时进行统计估计，汇总观察结果，并可视化统计模型的拟合以强调数据集中的模式

```bash
pip install seaborn
```

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

fn = r'..\res\fmri.csv'
ds = pd.read_csv(fn)

sns.set(style='darkgrid')
sns.relplot(x='timepoint', y='signal', hue='event', style='event', col='region', kind='line', data=ds)
plt.show()
```



























